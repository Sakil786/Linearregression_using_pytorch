{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "regression_using_pytorch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#importing necessary libraries\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "\n",
        "class StockDataset(torch.utils.data.Dataset):\n",
        "  '''\n",
        "  Prepare the Stock Price dataset for regression\n",
        "  '''\n",
        "\n",
        "  def __init__(self, X, y, scale_data=True):\n",
        "    self.X = torch.from_numpy(X)\n",
        "    self.y = torch.from_numpy(y)\n",
        "  def __len__(self):\n",
        "      return len(self.X)\n",
        "\n",
        "  def __getitem__(self, i):\n",
        "      return self.X[i], self.y[i]\n",
        "      \n",
        "\n",
        "class MLP(nn.Module):\n",
        "  '''\n",
        "    Multilayer Perceptron for regression.\n",
        "  '''\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "      nn.Linear(7, 64),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(64, 32),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(32, 1)\n",
        "    )\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    '''\n",
        "      Forward pass\n",
        "    '''\n",
        "    return self.layers(x)\n",
        "\n",
        "  \n",
        "if __name__ == '__main__':\n",
        "  \n",
        "  # Set fixed random number seed\n",
        "  torch.manual_seed(42)\n",
        "\n",
        "  #reading stock price data\n",
        "  data = pd.read_csv('/content/stock_price.csv')\n",
        "\n",
        "  #splitting the variable into dependent/independent variable\n",
        "  x = data[['SecuritiesCode', 'Open', 'High', 'Low', 'Close', 'Volume', 'AdjustmentFactor']]\n",
        "  Y = data['Target']\n",
        "\n",
        "  #converting into array\n",
        "  X=x.values\n",
        "  y=Y.values\n",
        "  # Prepare stock price  dataset\n",
        "  dataset = StockDataset(X, y)\n",
        "  trainloader = torch.utils.data.DataLoader(dataset, batch_size=10, shuffle=True, num_workers=8)\n",
        "  \n",
        "  # Initialize the MLP\n",
        "  mlp = MLP()\n",
        "  \n",
        "  # Define the loss function and optimizer\n",
        "  loss_function = nn.L1Loss()\n",
        "  optimizer = torch.optim.Adam(mlp.parameters(), lr=1e-4)\n",
        "  \n",
        "  # Run the training loop\n",
        "  for epoch in range(0, 5): \n",
        "    \n",
        "    # Print epoch\n",
        "    print(f'Starting epoch {epoch+1}')\n",
        "    \n",
        "    # Set current loss value\n",
        "    current_loss = 0.0\n",
        "    \n",
        "    # Iterate over the DataLoader for training data\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "      \n",
        "      # Get and prepare inputs\n",
        "      inputs, targets = data\n",
        "      inputs, targets = inputs.float(), targets.float()\n",
        "      targets = targets.reshape((targets.shape[0], 1))\n",
        "      \n",
        "      # Zero the gradients\n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      # Perform forward pass\n",
        "      outputs = mlp(inputs)\n",
        "      \n",
        "      # Compute loss\n",
        "      loss = loss_function(outputs, targets)\n",
        "      \n",
        "      # Perform backward pass\n",
        "      loss.backward()\n",
        "      \n",
        "      # Perform optimization\n",
        "      optimizer.step()\n",
        "      \n",
        "      # Print statistics\n",
        "      current_loss += loss.item()\n",
        "      if i % 10 == 0:\n",
        "          print('Loss after mini-batch %5d: %.3f' %\n",
        "                (i + 1, current_loss / 200))\n",
        "          current_loss = 0.0\n",
        "\n",
        "  # Process is complete.\n",
        "  print('<<<<<<<<<<<END OF TRAINING>>>>>>>>>>>>>>>>>>>>>>>>')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84R5p0Z0hemP",
        "outputId": "60edb500-1d7f-44c7-af1e-5bf3b264ac8b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss after mini-batch     1: 44.099\n",
            "Loss after mini-batch    11: 463.746\n",
            "Loss after mini-batch    21: 126.520\n",
            "Loss after mini-batch    31: 57.270\n",
            "Loss after mini-batch    41: 68.669\n",
            "Loss after mini-batch    51: 18.797\n",
            "Loss after mini-batch    61: 27.951\n",
            "Loss after mini-batch    71: 16.543\n",
            "Loss after mini-batch    81: 14.184\n",
            "Loss after mini-batch    91: 16.121\n",
            "Loss after mini-batch   101: 17.392\n",
            "Loss after mini-batch   111: 22.148\n",
            "Loss after mini-batch   121: 18.098\n",
            "Loss after mini-batch   131: 19.893\n",
            "Loss after mini-batch   141: 10.444\n",
            "Loss after mini-batch   151: 87.953\n",
            "Loss after mini-batch   161: 20.576\n",
            "Loss after mini-batch   171: 31.808\n",
            "Loss after mini-batch   181: 17.249\n",
            "Loss after mini-batch   191: 44.850\n",
            "Loss after mini-batch   201: 45.706\n",
            "Loss after mini-batch   211: 25.032\n",
            "Loss after mini-batch   221: 7.128\n",
            "Loss after mini-batch   231: 7.370\n",
            "Loss after mini-batch   241: 5.368\n",
            "Loss after mini-batch   251: 4.976\n",
            "Loss after mini-batch   261: 5.253\n",
            "Loss after mini-batch   271: 11.540\n",
            "Loss after mini-batch   281: 9.137\n",
            "Loss after mini-batch   291: 4.524\n",
            "Loss after mini-batch   301: 3.897\n",
            "Loss after mini-batch   311: 4.587\n",
            "Loss after mini-batch   321: 3.962\n",
            "Loss after mini-batch   331: 2.320\n",
            "Loss after mini-batch   341: 2.469\n",
            "Loss after mini-batch   351: 7.890\n",
            "Loss after mini-batch   361: 2.939\n",
            "Loss after mini-batch   371: 4.900\n",
            "Loss after mini-batch   381: 5.876\n",
            "Loss after mini-batch   391: 1.974\n",
            "Loss after mini-batch   401: 3.094\n",
            "Loss after mini-batch   411: 2.960\n",
            "Loss after mini-batch   421: 2.747\n",
            "Loss after mini-batch   431: 29.964\n",
            "Loss after mini-batch   441: 48.192\n",
            "Loss after mini-batch   451: 28.836\n",
            "Loss after mini-batch   461: 9.305\n",
            "Loss after mini-batch   471: 3.657\n",
            "Loss after mini-batch   481: 16.566\n",
            "Loss after mini-batch   491: 7.029\n",
            "Loss after mini-batch   501: 4.854\n",
            "Loss after mini-batch   511: 6.820\n",
            "Loss after mini-batch   521: 4.304\n",
            "Loss after mini-batch   531: 2.472\n",
            "Loss after mini-batch   541: 4.557\n",
            "Loss after mini-batch   551: 22.756\n",
            "Loss after mini-batch   561: 10.729\n",
            "Loss after mini-batch   571: 3.498\n",
            "Loss after mini-batch   581: 3.636\n",
            "Loss after mini-batch   591: 4.614\n",
            "Loss after mini-batch   601: 5.986\n",
            "Loss after mini-batch   611: 3.996\n",
            "Loss after mini-batch   621: 1.440\n",
            "Loss after mini-batch   631: 2.504\n",
            "Loss after mini-batch   641: 3.849\n",
            "Loss after mini-batch   651: 3.167\n",
            "Loss after mini-batch   661: 2.761\n",
            "Loss after mini-batch   671: 0.870\n",
            "Loss after mini-batch   681: 0.946\n",
            "Loss after mini-batch   691: 2.076\n",
            "Loss after mini-batch   701: 3.451\n",
            "Loss after mini-batch   711: 2.840\n",
            "Loss after mini-batch   721: 1.377\n",
            "Loss after mini-batch   731: 1.336\n",
            "Loss after mini-batch   741: 1.678\n",
            "Loss after mini-batch   751: 1.032\n",
            "Loss after mini-batch   761: 1.794\n",
            "Loss after mini-batch   771: 1.094\n",
            "Loss after mini-batch   781: 7.808\n",
            "Loss after mini-batch   791: 20.227\n",
            "Loss after mini-batch   801: 9.592\n",
            "Loss after mini-batch   811: 3.673\n",
            "Loss after mini-batch   821: 4.143\n",
            "Loss after mini-batch   831: 5.900\n",
            "Loss after mini-batch   841: 6.244\n",
            "Loss after mini-batch   851: 22.345\n",
            "Loss after mini-batch   861: 21.123\n",
            "Loss after mini-batch   871: 9.888\n",
            "Loss after mini-batch   881: 7.585\n",
            "Loss after mini-batch   891: 5.777\n",
            "Loss after mini-batch   901: 2.469\n",
            "Loss after mini-batch   911: 4.171\n",
            "Loss after mini-batch   921: 3.355\n",
            "Loss after mini-batch   931: 1.266\n",
            "Loss after mini-batch   941: 0.932\n",
            "Loss after mini-batch   951: 2.730\n",
            "Loss after mini-batch   961: 2.738\n",
            "Loss after mini-batch   971: 5.390\n",
            "Loss after mini-batch   981: 3.251\n",
            "Loss after mini-batch   991: 4.227\n",
            "Starting epoch 2\n",
            "Loss after mini-batch     1: 2.240\n",
            "Loss after mini-batch    11: 41.383\n",
            "Loss after mini-batch    21: 30.645\n",
            "Loss after mini-batch    31: 60.016\n",
            "Loss after mini-batch    41: 112.701\n",
            "Loss after mini-batch    51: 74.646\n",
            "Loss after mini-batch    61: 120.534\n",
            "Loss after mini-batch    71: 9.308\n",
            "Loss after mini-batch    81: 22.069\n",
            "Loss after mini-batch    91: 28.523\n",
            "Loss after mini-batch   101: 6.363\n",
            "Loss after mini-batch   111: 6.066\n",
            "Loss after mini-batch   121: 16.081\n",
            "Loss after mini-batch   131: 13.068\n",
            "Loss after mini-batch   141: 4.842\n",
            "Loss after mini-batch   151: 2.306\n",
            "Loss after mini-batch   161: 1.489\n",
            "Loss after mini-batch   171: 2.991\n",
            "Loss after mini-batch   181: 2.727\n",
            "Loss after mini-batch   191: 2.969\n",
            "Loss after mini-batch   201: 2.557\n",
            "Loss after mini-batch   211: 1.111\n",
            "Loss after mini-batch   221: 0.607\n",
            "Loss after mini-batch   231: 2.160\n",
            "Loss after mini-batch   241: 8.288\n",
            "Loss after mini-batch   251: 11.830\n",
            "Loss after mini-batch   261: 6.536\n",
            "Loss after mini-batch   271: 0.433\n",
            "Loss after mini-batch   281: 0.768\n",
            "Loss after mini-batch   291: 0.514\n",
            "Loss after mini-batch   301: 2.028\n",
            "Loss after mini-batch   311: 10.876\n",
            "Loss after mini-batch   321: 39.580\n",
            "Loss after mini-batch   331: 51.754\n",
            "Loss after mini-batch   341: 21.061\n",
            "Loss after mini-batch   351: 4.480\n",
            "Loss after mini-batch   361: 4.965\n",
            "Loss after mini-batch   371: 4.641\n",
            "Loss after mini-batch   381: 12.123\n",
            "Loss after mini-batch   391: 19.394\n",
            "Loss after mini-batch   401: 13.699\n",
            "Loss after mini-batch   411: 53.052\n",
            "Loss after mini-batch   421: 42.416\n",
            "Loss after mini-batch   431: 34.465\n",
            "Loss after mini-batch   441: 50.735\n",
            "Loss after mini-batch   451: 31.369\n",
            "Loss after mini-batch   461: 7.105\n",
            "Loss after mini-batch   471: 7.375\n",
            "Loss after mini-batch   481: 7.984\n",
            "Loss after mini-batch   491: 2.783\n",
            "Loss after mini-batch   501: 2.749\n",
            "Loss after mini-batch   511: 10.936\n",
            "Loss after mini-batch   521: 1.919\n",
            "Loss after mini-batch   531: 2.340\n",
            "Loss after mini-batch   541: 14.305\n",
            "Loss after mini-batch   551: 39.835\n",
            "Loss after mini-batch   561: 28.179\n",
            "Loss after mini-batch   571: 25.422\n",
            "Loss after mini-batch   581: 9.030\n",
            "Loss after mini-batch   591: 5.570\n",
            "Loss after mini-batch   601: 7.533\n",
            "Loss after mini-batch   611: 4.809\n",
            "Loss after mini-batch   621: 5.559\n",
            "Loss after mini-batch   631: 2.455\n",
            "Loss after mini-batch   641: 2.839\n",
            "Loss after mini-batch   651: 1.982\n",
            "Loss after mini-batch   661: 0.882\n",
            "Loss after mini-batch   671: 1.042\n",
            "Loss after mini-batch   681: 3.539\n",
            "Loss after mini-batch   691: 26.623\n",
            "Loss after mini-batch   701: 6.574\n",
            "Loss after mini-batch   711: 5.919\n",
            "Loss after mini-batch   721: 4.521\n",
            "Loss after mini-batch   731: 2.934\n",
            "Loss after mini-batch   741: 1.871\n",
            "Loss after mini-batch   751: 22.373\n",
            "Loss after mini-batch   761: 29.595\n",
            "Loss after mini-batch   771: 70.145\n",
            "Loss after mini-batch   781: 9.530\n",
            "Loss after mini-batch   791: 7.200\n",
            "Loss after mini-batch   801: 8.568\n",
            "Loss after mini-batch   811: 2.858\n",
            "Loss after mini-batch   821: 1.947\n",
            "Loss after mini-batch   831: 1.098\n",
            "Loss after mini-batch   841: 5.431\n",
            "Loss after mini-batch   851: 2.770\n",
            "Loss after mini-batch   861: 1.086\n",
            "Loss after mini-batch   871: 3.444\n",
            "Loss after mini-batch   881: 5.086\n",
            "Loss after mini-batch   891: 3.537\n",
            "Loss after mini-batch   901: 1.306\n",
            "Loss after mini-batch   911: 0.862\n",
            "Loss after mini-batch   921: 1.239\n",
            "Loss after mini-batch   931: 0.810\n",
            "Loss after mini-batch   941: 1.537\n",
            "Loss after mini-batch   951: 0.616\n",
            "Loss after mini-batch   961: 7.677\n",
            "Loss after mini-batch   971: 57.075\n",
            "Loss after mini-batch   981: 23.387\n",
            "Loss after mini-batch   991: 5.140\n",
            "Starting epoch 3\n",
            "Loss after mini-batch     1: 0.273\n",
            "Loss after mini-batch    11: 1.923\n",
            "Loss after mini-batch    21: 0.539\n",
            "Loss after mini-batch    31: 2.875\n",
            "Loss after mini-batch    41: 3.369\n",
            "Loss after mini-batch    51: 1.153\n",
            "Loss after mini-batch    61: 2.148\n",
            "Loss after mini-batch    71: 0.790\n",
            "Loss after mini-batch    81: 0.420\n",
            "Loss after mini-batch    91: 2.058\n",
            "Loss after mini-batch   101: 1.143\n",
            "Loss after mini-batch   111: 2.173\n",
            "Loss after mini-batch   121: 10.926\n",
            "Loss after mini-batch   131: 109.811\n",
            "Loss after mini-batch   141: 63.614\n",
            "Loss after mini-batch   151: 57.120\n",
            "Loss after mini-batch   161: 32.802\n",
            "Loss after mini-batch   171: 5.610\n",
            "Loss after mini-batch   181: 41.927\n",
            "Loss after mini-batch   191: 68.914\n",
            "Loss after mini-batch   201: 42.650\n",
            "Loss after mini-batch   211: 20.995\n",
            "Loss after mini-batch   221: 15.254\n",
            "Loss after mini-batch   231: 8.386\n",
            "Loss after mini-batch   241: 5.732\n",
            "Loss after mini-batch   251: 3.157\n",
            "Loss after mini-batch   261: 2.203\n",
            "Loss after mini-batch   271: 1.609\n",
            "Loss after mini-batch   281: 1.619\n",
            "Loss after mini-batch   291: 2.514\n",
            "Loss after mini-batch   301: 10.522\n",
            "Loss after mini-batch   311: 3.413\n",
            "Loss after mini-batch   321: 1.880\n",
            "Loss after mini-batch   331: 2.744\n",
            "Loss after mini-batch   341: 2.150\n",
            "Loss after mini-batch   351: 4.624\n",
            "Loss after mini-batch   361: 23.385\n",
            "Loss after mini-batch   371: 57.473\n",
            "Loss after mini-batch   381: 85.344\n",
            "Loss after mini-batch   391: 36.896\n",
            "Loss after mini-batch   401: 54.229\n",
            "Loss after mini-batch   411: 68.891\n",
            "Loss after mini-batch   421: 26.424\n",
            "Loss after mini-batch   431: 12.530\n",
            "Loss after mini-batch   441: 10.141\n",
            "Loss after mini-batch   451: 24.371\n",
            "Loss after mini-batch   461: 12.791\n",
            "Loss after mini-batch   471: 5.622\n",
            "Loss after mini-batch   481: 2.912\n",
            "Loss after mini-batch   491: 9.426\n",
            "Loss after mini-batch   501: 21.519\n",
            "Loss after mini-batch   511: 26.193\n",
            "Loss after mini-batch   521: 4.442\n",
            "Loss after mini-batch   531: 5.466\n",
            "Loss after mini-batch   541: 3.266\n",
            "Loss after mini-batch   551: 2.929\n",
            "Loss after mini-batch   561: 3.547\n",
            "Loss after mini-batch   571: 5.349\n",
            "Loss after mini-batch   581: 2.916\n",
            "Loss after mini-batch   591: 1.923\n",
            "Loss after mini-batch   601: 2.054\n",
            "Loss after mini-batch   611: 0.445\n",
            "Loss after mini-batch   621: 0.403\n",
            "Loss after mini-batch   631: 2.513\n",
            "Loss after mini-batch   641: 3.206\n",
            "Loss after mini-batch   651: 2.370\n",
            "Loss after mini-batch   661: 0.633\n",
            "Loss after mini-batch   671: 7.590\n",
            "Loss after mini-batch   681: 5.599\n",
            "Loss after mini-batch   691: 5.594\n",
            "Loss after mini-batch   701: 12.901\n",
            "Loss after mini-batch   711: 6.493\n",
            "Loss after mini-batch   721: 28.847\n",
            "Loss after mini-batch   731: 15.707\n",
            "Loss after mini-batch   741: 4.136\n",
            "Loss after mini-batch   751: 3.405\n",
            "Loss after mini-batch   761: 1.050\n",
            "Loss after mini-batch   771: 4.981\n",
            "Loss after mini-batch   781: 4.360\n",
            "Loss after mini-batch   791: 10.846\n",
            "Loss after mini-batch   801: 3.154\n",
            "Loss after mini-batch   811: 3.596\n",
            "Loss after mini-batch   821: 2.641\n",
            "Loss after mini-batch   831: 2.551\n",
            "Loss after mini-batch   841: 2.338\n",
            "Loss after mini-batch   851: 4.244\n",
            "Loss after mini-batch   861: 3.422\n",
            "Loss after mini-batch   871: 1.008\n",
            "Loss after mini-batch   881: 2.059\n",
            "Loss after mini-batch   891: 1.066\n",
            "Loss after mini-batch   901: 0.364\n",
            "Loss after mini-batch   911: 0.535\n",
            "Loss after mini-batch   921: 0.361\n",
            "Loss after mini-batch   931: 1.038\n",
            "Loss after mini-batch   941: 4.151\n",
            "Loss after mini-batch   951: 4.725\n",
            "Loss after mini-batch   961: 2.928\n",
            "Loss after mini-batch   971: 2.725\n",
            "Loss after mini-batch   981: 6.852\n",
            "Loss after mini-batch   991: 13.053\n",
            "Starting epoch 4\n",
            "Loss after mini-batch     1: 0.464\n",
            "Loss after mini-batch    11: 2.628\n",
            "Loss after mini-batch    21: 4.308\n",
            "Loss after mini-batch    31: 3.655\n",
            "Loss after mini-batch    41: 0.920\n",
            "Loss after mini-batch    51: 0.942\n",
            "Loss after mini-batch    61: 1.363\n",
            "Loss after mini-batch    71: 3.389\n",
            "Loss after mini-batch    81: 4.579\n",
            "Loss after mini-batch    91: 1.707\n",
            "Loss after mini-batch   101: 1.420\n",
            "Loss after mini-batch   111: 3.344\n",
            "Loss after mini-batch   121: 4.083\n",
            "Loss after mini-batch   131: 1.508\n",
            "Loss after mini-batch   141: 1.109\n",
            "Loss after mini-batch   151: 1.073\n",
            "Loss after mini-batch   161: 1.314\n",
            "Loss after mini-batch   171: 7.579\n",
            "Loss after mini-batch   181: 4.771\n",
            "Loss after mini-batch   191: 3.807\n",
            "Loss after mini-batch   201: 3.127\n",
            "Loss after mini-batch   211: 8.054\n",
            "Loss after mini-batch   221: 64.704\n",
            "Loss after mini-batch   231: 200.831\n",
            "Loss after mini-batch   241: 44.679\n",
            "Loss after mini-batch   251: 19.332\n",
            "Loss after mini-batch   261: 10.079\n",
            "Loss after mini-batch   271: 15.508\n",
            "Loss after mini-batch   281: 19.537\n",
            "Loss after mini-batch   291: 28.387\n",
            "Loss after mini-batch   301: 6.422\n",
            "Loss after mini-batch   311: 11.258\n",
            "Loss after mini-batch   321: 3.259\n",
            "Loss after mini-batch   331: 4.885\n",
            "Loss after mini-batch   341: 8.782\n",
            "Loss after mini-batch   351: 3.676\n",
            "Loss after mini-batch   361: 2.932\n",
            "Loss after mini-batch   371: 0.886\n",
            "Loss after mini-batch   381: 3.168\n",
            "Loss after mini-batch   391: 2.187\n",
            "Loss after mini-batch   401: 2.326\n",
            "Loss after mini-batch   411: 0.820\n",
            "Loss after mini-batch   421: 2.030\n",
            "Loss after mini-batch   431: 5.567\n",
            "Loss after mini-batch   441: 6.591\n",
            "Loss after mini-batch   451: 6.427\n",
            "Loss after mini-batch   461: 6.858\n",
            "Loss after mini-batch   471: 8.219\n",
            "Loss after mini-batch   481: 2.787\n",
            "Loss after mini-batch   491: 1.958\n",
            "Loss after mini-batch   501: 2.050\n",
            "Loss after mini-batch   511: 1.485\n",
            "Loss after mini-batch   521: 1.560\n",
            "Loss after mini-batch   531: 2.559\n",
            "Loss after mini-batch   541: 1.392\n",
            "Loss after mini-batch   551: 8.903\n",
            "Loss after mini-batch   561: 17.000\n",
            "Loss after mini-batch   571: 14.033\n",
            "Loss after mini-batch   581: 15.267\n",
            "Loss after mini-batch   591: 1.906\n",
            "Loss after mini-batch   601: 8.515\n",
            "Loss after mini-batch   611: 4.648\n",
            "Loss after mini-batch   621: 1.501\n",
            "Loss after mini-batch   631: 1.094\n",
            "Loss after mini-batch   641: 0.281\n",
            "Loss after mini-batch   651: 0.521\n",
            "Loss after mini-batch   661: 0.893\n",
            "Loss after mini-batch   671: 2.281\n",
            "Loss after mini-batch   681: 4.350\n",
            "Loss after mini-batch   691: 2.618\n",
            "Loss after mini-batch   701: 4.370\n",
            "Loss after mini-batch   711: 112.217\n",
            "Loss after mini-batch   721: 17.711\n",
            "Loss after mini-batch   731: 2.626\n",
            "Loss after mini-batch   741: 1.983\n",
            "Loss after mini-batch   751: 0.547\n",
            "Loss after mini-batch   761: 0.716\n",
            "Loss after mini-batch   771: 2.342\n",
            "Loss after mini-batch   781: 60.814\n",
            "Loss after mini-batch   791: 76.060\n",
            "Loss after mini-batch   801: 32.179\n",
            "Loss after mini-batch   811: 29.930\n",
            "Loss after mini-batch   821: 5.496\n",
            "Loss after mini-batch   831: 4.749\n",
            "Loss after mini-batch   841: 2.563\n",
            "Loss after mini-batch   851: 1.781\n",
            "Loss after mini-batch   861: 1.640\n",
            "Loss after mini-batch   871: 5.366\n",
            "Loss after mini-batch   881: 6.653\n",
            "Loss after mini-batch   891: 1.336\n",
            "Loss after mini-batch   901: 1.612\n",
            "Loss after mini-batch   911: 0.857\n",
            "Loss after mini-batch   921: 0.740\n",
            "Loss after mini-batch   931: 3.698\n",
            "Loss after mini-batch   941: 16.596\n",
            "Loss after mini-batch   951: 17.058\n",
            "Loss after mini-batch   961: 7.713\n",
            "Loss after mini-batch   971: 2.032\n",
            "Loss after mini-batch   981: 2.654\n",
            "Loss after mini-batch   991: 1.534\n",
            "Starting epoch 5\n",
            "Loss after mini-batch     1: 0.064\n",
            "Loss after mini-batch    11: 2.725\n",
            "Loss after mini-batch    21: 2.796\n",
            "Loss after mini-batch    31: 0.981\n",
            "Loss after mini-batch    41: 10.105\n",
            "Loss after mini-batch    51: 12.402\n",
            "Loss after mini-batch    61: 2.611\n",
            "Loss after mini-batch    71: 2.960\n",
            "Loss after mini-batch    81: 1.489\n",
            "Loss after mini-batch    91: 1.561\n",
            "Loss after mini-batch   101: 1.021\n",
            "Loss after mini-batch   111: 0.562\n",
            "Loss after mini-batch   121: 2.665\n",
            "Loss after mini-batch   131: 4.300\n",
            "Loss after mini-batch   141: 7.291\n",
            "Loss after mini-batch   151: 19.649\n",
            "Loss after mini-batch   161: 9.414\n",
            "Loss after mini-batch   171: 18.627\n",
            "Loss after mini-batch   181: 4.610\n",
            "Loss after mini-batch   191: 74.575\n",
            "Loss after mini-batch   201: 78.541\n",
            "Loss after mini-batch   211: 73.420\n",
            "Loss after mini-batch   221: 23.518\n",
            "Loss after mini-batch   231: 7.388\n",
            "Loss after mini-batch   241: 9.160\n",
            "Loss after mini-batch   251: 5.123\n",
            "Loss after mini-batch   261: 5.428\n",
            "Loss after mini-batch   271: 3.150\n",
            "Loss after mini-batch   281: 1.145\n",
            "Loss after mini-batch   291: 0.971\n",
            "Loss after mini-batch   301: 7.762\n",
            "Loss after mini-batch   311: 15.741\n",
            "Loss after mini-batch   321: 10.285\n",
            "Loss after mini-batch   331: 6.033\n",
            "Loss after mini-batch   341: 5.555\n",
            "Loss after mini-batch   351: 3.743\n",
            "Loss after mini-batch   361: 2.158\n",
            "Loss after mini-batch   371: 1.363\n",
            "Loss after mini-batch   381: 0.651\n",
            "Loss after mini-batch   391: 0.792\n",
            "Loss after mini-batch   401: 0.641\n",
            "Loss after mini-batch   411: 0.570\n",
            "Loss after mini-batch   421: 0.573\n",
            "Loss after mini-batch   431: 0.389\n",
            "Loss after mini-batch   441: 0.729\n",
            "Loss after mini-batch   451: 0.511\n",
            "Loss after mini-batch   461: 0.814\n",
            "Loss after mini-batch   471: 1.842\n",
            "Loss after mini-batch   481: 0.509\n",
            "Loss after mini-batch   491: 0.687\n",
            "Loss after mini-batch   501: 3.867\n",
            "Loss after mini-batch   511: 5.831\n",
            "Loss after mini-batch   521: 4.205\n",
            "Loss after mini-batch   531: 56.150\n",
            "Loss after mini-batch   541: 50.317\n",
            "Loss after mini-batch   551: 26.869\n",
            "Loss after mini-batch   561: 18.802\n",
            "Loss after mini-batch   571: 33.513\n",
            "Loss after mini-batch   581: 100.536\n",
            "Loss after mini-batch   591: 128.221\n",
            "Loss after mini-batch   601: 70.777\n",
            "Loss after mini-batch   611: 6.998\n",
            "Loss after mini-batch   621: 15.102\n",
            "Loss after mini-batch   631: 5.570\n",
            "Loss after mini-batch   641: 3.498\n",
            "Loss after mini-batch   651: 7.501\n",
            "Loss after mini-batch   661: 4.131\n",
            "Loss after mini-batch   671: 1.833\n",
            "Loss after mini-batch   681: 1.512\n",
            "Loss after mini-batch   691: 0.608\n",
            "Loss after mini-batch   701: 1.264\n",
            "Loss after mini-batch   711: 1.136\n",
            "Loss after mini-batch   721: 7.290\n",
            "Loss after mini-batch   731: 2.099\n",
            "Loss after mini-batch   741: 2.073\n",
            "Loss after mini-batch   751: 2.788\n",
            "Loss after mini-batch   761: 2.956\n",
            "Loss after mini-batch   771: 1.868\n",
            "Loss after mini-batch   781: 0.638\n",
            "Loss after mini-batch   791: 0.921\n",
            "Loss after mini-batch   801: 1.550\n",
            "Loss after mini-batch   811: 1.589\n",
            "Loss after mini-batch   821: 1.135\n",
            "Loss after mini-batch   831: 0.573\n",
            "Loss after mini-batch   841: 2.971\n",
            "Loss after mini-batch   851: 3.442\n",
            "Loss after mini-batch   861: 14.994\n",
            "Loss after mini-batch   871: 6.473\n",
            "Loss after mini-batch   881: 2.469\n",
            "Loss after mini-batch   891: 0.675\n",
            "Loss after mini-batch   901: 2.391\n",
            "Loss after mini-batch   911: 5.538\n",
            "Loss after mini-batch   921: 4.707\n",
            "Loss after mini-batch   931: 6.528\n",
            "Loss after mini-batch   941: 9.768\n",
            "Loss after mini-batch   951: 7.593\n",
            "Loss after mini-batch   961: 1.959\n",
            "Loss after mini-batch   971: 1.170\n",
            "Loss after mini-batch   981: 6.093\n",
            "Loss after mini-batch   991: 35.002\n",
            "<<<<<<<<<<<END OF TRAINING>>>>>>>>>>>>>>>>>>>>>>>>\n"
          ]
        }
      ]
    }
  ]
}